#!/usr/bin/env python3
"""
Demonstrate Newton.RS LLM integration with OpenAI and Ollama
"""

import sys
import os
sys.path.append('/home/runner/workspace')

from logicbridge.llm_generator import RuleGenerator
from logicbridge.core import RuleEngine
import yaml
import json

def test_mock_rule_generation():
    """Test mock rule generation for common business scenarios"""
    print("Testing Mock Rule Generation:")
    print("=" * 50)
    
    # Initialize mock generator
    generator = RuleGenerator(provider="mock", model="test_model")
    
    # Test various business scenarios
    test_stories = [
        "Premium customers should get a 20% discount on orders over $500",
        "High-risk transactions need immediate fraud team review",
        "VIP customers deserve priority support and expedited processing",
        "Medical insurance claims over $10,000 require specialist approval",
        "Loan applications with excellent credit scores get fast-track processing"
    ]
    
    for i, story in enumerate(test_stories, 1):
        print(f"\nTest {i}: {story}")
        rules = generator.generate_from_stories([story])
        
        # Display generated rules
        for rule in rules["rules"]:
            print(f"  Generated Rule: {rule['id']}")
            print(f"  Description: {rule['description']}")
            print(f"  Tags: {', '.join(rule['tags'])}")
            print(f"  Decision: {rule['then']['outcome']['decision']}")
            
            # Test the generated rule
            engine = RuleEngine()
            engine.load_ruleset_from_yaml(yaml.dump(rules))
            
            # Create test payload based on rule type
            if "discount" in rule['tags']:
                test_payload = {"order_total": 600, "customer_tier": "premium"}
            elif "risk" in rule['tags']:
                test_payload = {"transaction_amount": 15000, "risk_score": "high"}
            elif "premium" in rule['tags']:
                test_payload = {"customer_tier": "premium"}
            else:
                test_payload = {"status": "active"}
                
            decision = engine.evaluate(test_payload)
            if decision:
                print(f"  Test Result: Rule triggered - {decision.outcome}")
            else:
                print(f"  Test Result: Rule not triggered with test payload")

def test_openai_integration():
    """Test OpenAI integration if API key is available"""
    print("\n\nTesting OpenAI Integration:")
    print("=" * 50)
    
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("OPENAI_API_KEY not available - skipping OpenAI tests")
        print("To test OpenAI integration, set the OPENAI_API_KEY environment variable")
        return
    
    try:
        generator = RuleGenerator(provider="openai", model="gpt-4o")
        print("OpenAI client initialized successfully")
        
        story = "Premium customers with orders over $300 should get 12% discount"
        print(f"Generating rules for: {story}")
        
        rules = generator.generate_from_stories([story])
        print(f"Generated {len(rules['rules'])} rules successfully")
        
        for rule in rules["rules"]:
            print(f"  Rule ID: {rule['id']}")
            print(f"  LLM Model: {rule['llm_model']}")
            print(f"  Generated by LLM: {rule['generated_by_llm']}")
            
    except Exception as e:
        print(f"OpenAI integration test failed: {e}")
        print("This may be due to API key issues or network connectivity")

def test_ollama_integration():
    """Test Ollama integration if server is available"""
    print("\n\nTesting Ollama Integration:")
    print("=" * 50)
    
    try:
        generator = RuleGenerator(provider="ollama", model="llama2")
        print("Ollama client initialized successfully")
        
        story = "Insurance claims over $5000 need manager approval"
        print(f"Generating rules for: {story}")
        
        rules = generator.generate_from_stories([story])
        print(f"Generated {len(rules['rules'])} rules successfully")
        
        for rule in rules["rules"]:
            print(f"  Rule ID: {rule['id']}")
            print(f"  LLM Model: {rule['llm_model']}")
            
    except Exception as e:
        print(f"Ollama integration test failed: {e}")
        print("This may be due to Ollama server not running or connectivity issues")
        print("To test Ollama, ensure Ollama is installed and running on localhost:11434")

def demonstrate_rule_validation():
    """Demonstrate comprehensive rule validation"""
    print("\n\nTesting Rule Validation:")
    print("=" * 50)
    
    from logicbridge.validation import validate_complete_ruleset
    
    # Test valid ruleset
    valid_rules = {
        "rules": [
            {
                "id": "test_rule",
                "description": "Test validation rule",
                "when": {
                    "type": "equals",
                    "field": "status",
                    "value": "active"
                },
                "then": {
                    "outcome": {
                        "decision": "approve"
                    }
                }
            }
        ],
        "version": "1.0"
    }
    
    try:
        validate_complete_ruleset(yaml.dump(valid_rules), "yaml")
        print("Valid ruleset passed all validation checks")
    except Exception as e:
        print(f"Validation failed: {e}")
    
    # Test invalid ruleset
    invalid_rules = {
        "rules": [
            {
                "id": "invalid_rule",
                "when": {
                    "type": "unknown_type",
                    "field": "status"
                }
                # Missing 'then' field
            }
        ]
    }
    
    try:
        validate_complete_ruleset(yaml.dump(invalid_rules), "yaml")
        print("Invalid ruleset incorrectly passed validation")
    except Exception as e:
        print(f"Invalid ruleset correctly rejected: {str(e)[:100]}...")

def main():
    """Run all LLM integration demonstrations"""
    print("LogicBridge LLM Integration Demonstration")
    print("=" * 60)
    
    test_mock_rule_generation()
    test_openai_integration()
    test_ollama_integration()
    demonstrate_rule_validation()
    
    print("\n\nLLM Integration Demonstration Complete!")
    print("=" * 60)
    print("LogicBridge supports:")
    print("• Mock rule generation for testing and development")
    print("• OpenAI GPT models for production rule generation")
    print("• Ollama for local/private LLM deployment")
    print("• Comprehensive rule validation and safety checks")
    print("• Audit logging with SHA-based versioning")

if __name__ == "__main__":
    main()